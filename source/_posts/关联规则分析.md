---
title: 关联规则分析
date: 2018-08-14 21:38:48
tags: [机器学习,association analysis]
categories: 机器学习
---

这两天做了两道笔试题，第一道题是常规的结构化数据分类问题，用一个觉得效果最好的分类算法来算AUC，
并给出参数优化的过程。
第二题我之前还没有碰到过类似的问题，是对结构化的数据进行挖掘，找出其中的association rules，并且Rule
的左侧少于等于两项，Support在0.1以上，Confidence在0.7以上。
<!-- more -->
# 关联规则分析

整个过程是：
1. 先对原始数据进行处理，将值和特征名称组合起来构成新的词项
2. 将原始的DataFrame转换成为提取频繁项集时所需要的列表
3. 采用Apriori算法或者FP-growth算法生成频繁项集
4. 对频繁项集进行规则查找

# Apriori算法

## 原理

如果某个项集是频繁的，那么它的所有子集势必也是频繁的，这个原理从表面上看没什么大用，但是反过来，如果一个项集是非频繁项集，
那么它所对应的超集就全都是非频繁项集。这样在确定了一个项集是非频繁项集了之后，它所对应的超集的支持度我们就可以不去计算了，
这在很大程度上避免了项集数目的指数增长，可以更加合理的计算频繁项集。

## 实现过程

(1) 发现频繁项集

Apriori算法的两个输入参数分别是最小支持度和数据集。该算法首先生成所有单个物品的项集列表，遍历之后去掉不满足最小支持度要求
的项集；接下来对剩下的集合进行组合生成包含两个元素的项集，去掉不满足最小支持度的项集；重复该过程直到去掉所有不满足最小支
持度的项集。

(2) 从频繁项集中挖掘关联规则

假设有一个频繁项集，它们之间就有可能有一条关联规则，即可以表示为："...—>..."，但反过来并不一定成立（其中箭头左边对应的集合为前件，箭头右边对应的集合为后件）。
在上一节，我们使用最小支持度来量化频繁项集，对应的，采用可信度来量化关联规则。其中一条规则p—>H的可信度定义为：support(P|H)/support(P)，为找到其中的关联规则，
我们可以先生成一个可能的规则列表，然后测试每条规则的可信度，结合可信度的最小要求，得到关联规则。同寻找频繁项集类似，我们可以为每个频繁项集产生许多关联规则，
这样就会有很多的关联规则产生。结合Apriori原理，如果某条规则不满足最小可信度要求，那么该规则的所有子集也就不满足最小可信度要求，据此我们可以减少需要测试的规则数目，简化问题。
寻找关联规则的思想是：从一个频繁项集开始，创建一个规则列表，首先将规则的右边限定为一个元素，对这些规则进行测试，接下来合并剩下的规则来创建一个新的规则列表，
规则的右边限定为两个元素，就这样一步一步实现。


# FP-growth算法

FP-growth(Frequent Pattern Growth，频繁模式增长)，它比Apriori算法效率更高，在整个算法执行过程中，只需要遍历数据集2次，就
可完成频繁模式的发现。

## 计算过程

(1) 创建FP-tree

对于输入的dataset，统计所有事项中各元素的出现频次，即各个1项集的频数，并将各元素按照频数降序排序，删除那些出现频数少于设定
支持度sup的元素，形成列表L，留下来的元素就构成了频繁1项集。(这是对数据集的第一遍扫描)

对数据集中每个事物的元素按照列表L排序(按支持度降序排列)，开始构造FP-tree。树的根节点为空，每个事务中的所有元素形成一条
从根节点到叶子节点的路径。若几个事务的元素按列表L排序后，具有相同的前m个元素，则它们在FP-tree中共享前m个元素代表的节点。
树中每个节点的计数为路径经过该节点的事务集的个数。(这是对数据集的第二遍扫描)

在创建FP-tree的同时，headTable也就创建好了，headTable可以理解为一个具有三列的表。第一列为元素(项ID)，第二列为支持度计数，
第三列为节点链。如下所示

项ID | 支持度计数 | 节点链 
- | :-: | -: 
啤酒 | 4 | nodelink1
尿不湿 | 3 | nodelink2
... | ... | ...
牛奶 | 2 | nodelinkn

headTable中的项也是按照支持度计数从大到小排列的。节点链则链接到FP-tree中这一项所在的各个叶子结点上，后面频繁项集的发现就是靠的这些节点链。

(2) 寻找FP

从headTable中的最后一行开始，依次往上取项，比如最开始我们取‘牛奶’。寻找‘牛奶’的所有前缀路径，这些前缀路径形成‘牛奶’的CPB(Condition Pattern Base，条件模式基)，
而这些CPB又形成新的事务数据库。将‘牛奶’这一项添加到我们的集合中，此时，‘牛奶’这个频繁1-项集的支持度就是headTable中的支持度计数。然后用‘牛奶’的CPB形成的事务数据构造FP-tree，
构造的过程中将不满足支持度的项删除，而满足支持度的项又会构成另外一个FP-tree和headTable，我们记为FP-tree1和headTable1。同样的从headTable1的最后一行开始，
比如是可乐，那么把‘可乐’和之前的‘牛奶’就形成了频繁2-项集，此时，{‘牛奶’，‘可乐’}这个频繁2-项集的支持度就是headTable1中‘可乐’的支持度。
同时，我们也要寻找‘可乐’的前缀路径形成的CPB构成的又一个事务数据集，仍旧是构造FP-tree，从headTable取元素项，将元素项加集合

所以，FP的发现过程就是一个循环里不断递归的操作。循环，循环的是headTable中的各个元素项；递归，递归的是元素项的CPB构成的事务数据集形成的FP-tree中发现FP。

原理就介绍到这，下面是具体实践。

经过一番搜索，我查到两种算法对应的实现过程如下：
* pymining：根据Apriori算法进行关联规则挖掘
* Orange3：根据FP-growth算法进行关联规则挖掘
但是按照CSDN上的教程实现下来出现了一些问题，在提取频繁项集的时候报错提示输入应该是int型的列表，但是教程中输入的是
str型的列表，花了很久也没有解决，随放弃。

后来采用apyori.apriori来进行处理，得到了结果，但是在运行过程中炒鸡慢 = = 我一度怀疑是我的代码写的有问题，最终只跑了
两侧各为1的Rule，代码如下：
``` python
# -*- coding: utf-8 -*-
"""
Created on Mon Aug 13 21:47:59 2018

@author: ims
"""

import pandas as pd
from apyori import apriori
import numpy as np
import time

# 加载数据
start_time = time.time()
df = pd.read_csv(r'Test2_data.csv')

# 将原始数据处理组合出新词项后生成列表
transactions = []
listToStore = []
for i in range(df.iloc[:,0].size):             #df.iloc[:,0].size
    for col in df.columns:
        s = df.iloc[i][col]
        s = str(s)
        s = col + '_' + s
        listToStore.append(s)
    transactions.append(listToStore)
    print(i)
    listToStore = []

# 利用apriori算法生成规则
rules = apriori(transactions,min_support=0.1,min_confidence=0.7,min_lift=1,max_length=2)
results = list(rules)
final_results = pd.DataFrame(np.random.randint(low=0,high=1,size=(len(results),6)),columns=['GeneralRules',\
                             'LeftRules','RightRules','Support','Confidence','Lift'])

# 将规则提取成dataframe形式
index = 0
for g, s, i in results:
    final_results.iloc[index] = [' _&&_ '.join(list(g)), ' _&&_ '.join(list(i[0][0])), ' _&&_ '.join(list(i[0][1])), s, i[0][2], i[0][3]]
    index = index + 1
final_results = final_results.sort_values('Lift',ascending=0)
final_rules = final_results[final_results['RightRules']=='Label']
end_time = time.time()
print('The total time is:{}'.format(end_time-start_time))
```
提取出的规则如图：
### 正向规则
![png](/img/rule1.png)
### 反向规则
![png](/img/rule2.png)


## 参考文献
- [使用python进行数据关联分析](https://blog.csdn.net/qq_19528953/article/details/79412245)
- [Online Retail Analyze With Association Rules](https://www.kaggle.com/asamir/online-retail-analyze-with-association-rules/notebook)
- 机器学习实战，Peter Harrington
